<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Testing-with-mocha-chai-sinon : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Testing with Mocha, Chai, and Sinon</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/loganbfisher/testing-with-mocha-chai-sinon">View on GitHub</a>
        </header>
        <h1>Testing with Mocha, Chai, and Sinon</h1>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
<p>We will be using Mocha to run tests, Chai to spy on functions, and Sinon to stub 3rd party functionality.  Below are links to each one of the projects.  Please read into their functionality and why or how you would use them before continuing forward.</p>
<h3><a id="Mocha_4"></a>Mocha:</h3>
<p><a href="https://mochajs.org/">https://mochajs.org/</a></p>
<h3><a id="Sinon_7"></a>Sinon:</h3>
<p><a href="http://sinonjs.org/">http://sinonjs.org/</a></p>
<h3><a id="Chai_10"></a>Chai:</h3>
<p><a href="http://chaijs.com/">http://chaijs.com/</a></p>
<h2><a id="Writing_your_unit_tests_13"></a>Writing your unit tests:</h2>
<p>To start a new test create a file called <code>name_of_file_test.js</code> inside the tests folder of your repo.  Make sure you keep the same folder structure as you do in the actual codebase.  So for example if your file to test is located in <code>commands/file_system</code> you would mirror that structure in the tests folder.</p>
<p>You should also include the file your testing.  So in this example I am testing the folder_command.js file.  I would require this at the top of the test file like so</p>
<p><code>var FolderCommand = require('../../../commands/file_system/folder_command');</code></p>
<p>This gives you the ability to call the functions you will be testing.</p>
<p>From here you should be setup to start writing your unit tests. Congrats!</p>
<h2><a id="Using_Sinon_stubs_in_your_test_24"></a>Using Sinon stubs in your test</h2>
<p>Let’s start with an example.</p>
<p>This is the function we will be testing.</p>
<pre><code>module.exports.create = function (options) {
  const directory = options.timeStamp + '--' + options.id;

  return Q.nfcall(fs.mkdir, directory);
};
</code></pre>
<p>We want to be able to make sure that <code>Q.nfcall</code> was call with specific argument but we dont want <code>fs.mkdir</code> to actually make a directory so we use stubs.</p>
<p>Here is what the test would look like. Please disregard the chai.spy.on call until later.</p>
<pre><code>describe('FolderCommand', function() {
  describe('.create', function() {
    beforeEach(function() {
      Test.sinon.stub(fs, 'mkdir');
      Test.chai.spy.on(Q, 'nfcall');
    });

    it('call Q.nfcall with args', function() {
      FolderCommand.create(options);
      Test.expect(Q.nfcall).to.have.been.called.with(fs.mkdir, directory);
    });
  });
});
</code></pre>
<h2><a id="Using_Chai_Spys_in_your_test_53"></a>Using Chai Spys in your test</h2>
<p>Let’s start with an example.</p>
<p>This is the function we will be testing.</p>
<pre><code>module.exports.create = function (options) {
  const directory = options.timeStamp + '--' + options.id;

  return Q.nfcall(fs.mkdir, directory);
};
</code></pre>
<p>We want to be able to make sure that <code>Q.nfcall</code> was call with specific argument.  To do this we have to spy on the function and then expect it to be called.</p>
<p>Here is what the test would look like.</p>
<pre><code>describe('FolderCommand', function() {
  describe('.create', function() {
    beforeEach(function() {
      Test.sinon.stub(fs, 'mkdir');
      Test.chai.spy.on(Q, 'nfcall');
    });

    it('call Q.nfcall with args', function() {
      FolderCommand.create(options);
      Test.expect(Q.nfcall).to.have.been.called.with(fs.mkdir, directory);
    });
  });
});
</code></pre>
<p>You can see what in the <code>beforeEach</code> we are calling <code>Test.chai.spy.on(Q, 'nfcall')</code>.  This allows us to expect the function to be called with the args you are passing in.</p>
<h2><a id="Testing_asynchronous_code_84"></a>Testing asynchronous code:</h2>
<p>This is my example function under test:</p>
<pre><code>module.exports.create = function (options) {
 const directory = options.timeStamp + '--' + options.id + '/' + options.id + '--' + options.key  + options.ext;

 return Q.nfcall(json2csv, _configureOptions(options.ext, options.data, _reportFields())).then(function(csv) {
   return Q.nfcall(fs.writeFile, directory, csv, 'utf8');
 });
}
</code></pre>
<p>You can see that we are calling <code>Q.nfcall(json2csv....)</code> and then when it returns the promise we are calling <code>Q.nfcall(fs.writeFile.....)</code>.  Since we are doing this we can’t simply call the function and then expect something to happen on the next line.  In our test we will have to call the function and then call <code>then</code> on it and expect it to be called there.</p>
<p>Here is an example of how the test would look.</p>
<pre><code>describe('CsvCommand', function() {
  describe('.create', function() {
    let sandbox;

    beforeEach(function () {
      sandbox = Test.sinon.sandbox.create();
      let stub = sandbox.stub(Q, 'nfcall');
      stub.onFirstCall().returns(Q.resolve(csv));
      stub.onSecondCall();
      sandbox.stub(fs, 'writeFile');
      Test.chai.spy.on(Q, 'nfcall');
    });

    afterEach(function () {
      sandbox.restore();
    });

    it('should call Q.nfcall with fs.writeFile', function(done) {
      CsvCommand.create(options).then(function(data) {
        Test.expect(Q.nfcall).to.have.been.called.with(fs.writeFile, directory, csv, 'utf8');
        done();
      });
    });
  });
});
</code></pre>
<p>When testing promises the <code>it</code> block gives you a done argument you can use to tell your tests when the async code is done.  You need to make sure you call that directly after your expect line.</p>
<p>It’s important to note that we are using a <code>sandbox</code> here to be able to encapsulate this test and clean up the data after the test is run.  If you don’t use a <code>sandbox</code> then other tests files could potentially fail.</p>
<p>It’s also important to note that since we are calling <code>Q.nfcall</code> twice (one inside the other).  We have to stub it out twice and define <code>onFirstCall</code> and <code>onSecondCall</code>.  You will see that <code>onFirstCall</code> I am resolving the csv data just like the code does.  Then on the second call is where I am expecting the args to be what they should be. (Took me forever to figure this out…)</p>
<p>Also make sure that you use the afterEach function to restore your sandbox.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Testing-with-mocha-chai-sinon maintained by <a href="https://github.com/loganbfisher">loganbfisher</a></p>
        <p>Published with <a href="https://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
